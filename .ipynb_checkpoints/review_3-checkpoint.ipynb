{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53b8f72e-37b9-4339-889e-c1640bf4d7ce",
   "metadata": {},
   "source": [
    "# DSCI 100 Quiz 3 Review\n",
    "\n",
    "> ## Author: Owen Kwong\n",
    "\n",
    "### Loading relevant packages for notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3671abfc-5e94-479b-9fea-a15131a44161",
   "metadata": {},
   "source": [
    "## Chapter 11: Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e225393f-838d-4eba-bc48-b47443883b1c",
   "metadata": {},
   "source": [
    "### 11.1 Overview of Clustering\n",
    "\n",
    "Clustering is an exploratory data analysis to see if there are meaningful clusters/subgroups in the data. Learning objectives from this chapter are centered around using K-means algorithm: \n",
    "- Describe what kind of situation is appropriate to use clustering in and what insight it may extract\n",
    "- Explain K-means clustering algorithm \n",
    "- Interpret the output of K-means analysis \n",
    "- Differentiate between clusering and classification \n",
    "- Identify the need to and conduct scaling \n",
    "- Perform K-means clustering \n",
    "- Use the elbow graphing method to determine best K value \n",
    "- Visualize output of K-means in R using colored scatter plots \n",
    "- Describe advantages, limitations, and assumptions of K-means algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c17a3f8-6321-4241-8363-916982e9b4aa",
   "metadata": {},
   "source": [
    "### 11.2 Clustering process and K-means\n",
    "\n",
    "Clustering is an unsupervised task with questionable quality but the course does not go in-depth about this because it is complex. K-means clustering works by making an initial clustering and then improving the assignment until it cannot be improved further. In K-means clustering, quality is measured by *within-cluster sum-of-squared-distances* (WSSD). Two steps for this are: \n",
    "\n",
    "$$ μ_{x} = \\frac{1}{4}(x_{1}+x_{2}+x_{3}+x_{4}) \\ μ_{y} = \\frac{1}{4}(y_{1}+y_{2}+y_{3}+y_{4}) $$ \n",
    "\n",
    "Then, the second step is to calculate WSSD to add up squared distance between each point in the cluster and the cluster center. Therefore, the straight line distance WSSD for aboe would be: \n",
    "\n",
    "$$ S^2 = ((x_{1} - μ_{x})^2 + (y_{1} - μ_{y})^2) + ((x_{2} - μ_{x})^2 + (y_{2} - μ_{y})^2) + ((x_{3} - μ_{x})^2 + (y_{3} - μ_{y})^2) + ((x_{4} - μ_{x})^2 + (y_{4} - μ_{y})^2) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f087128-210c-469a-8e67-4e8888739601",
   "metadata": {},
   "source": [
    "**The algorithm** \n",
    "\n",
    "Three total steps: \n",
    "- Begins by assigning equal observations to each K cluster randomly then does next two steps repeatedly: \n",
    "1. **Center Update:** Compute the center of each cluster \n",
    "2. **Label Update:** Reassign each point to the cluster with the nearest center\n",
    "\n",
    "Note: \n",
    "\n",
    "- This algorithm is guaranteed to stop after some number of iterations. \n",
    "- Bad clustering can be solved by randomly re-initializing a few times and picking one with lowest WSSD\n",
    "\n",
    "**The algorithm** \n",
    "\n",
    "To choose number of clusters you graph WSSD for a range of number of clusters. Then, plot total WSSD against number of clusters and select WSSD point that is the \"elbow\" of the plot. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a994eab-5cdd-4576-8883-81215fb607b1",
   "metadata": {},
   "source": [
    "### 11.3 Data Preprocessing \n",
    "\n",
    "Clustering requires straight-line distance to determine which points are similar. Due to this, we have to scale the data: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98bb76f-eb5d-44af-b434-195b173b7dc1",
   "metadata": {},
   "source": [
    "**Example code:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5983ef0a-a932-488f-b42b-0c96cd37261f",
   "metadata": {},
   "source": [
    "```\n",
    "not_standardized_data <- read_csv(\"data/penguins_not_standardized.csv\") #(1)\n",
    "\n",
    "standardized_data <- not_standardized_data |> #(2)\n",
    "  mutate(across(everything(), scale))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10696729-c760-4db2-8f02-95c859c2f168",
   "metadata": {},
   "source": [
    "1. Reads csv file and assigns to variable\n",
    "2. mutates accross the whole tibble scaling all the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4235c521-bb47-4171-97f2-d07b191e8997",
   "metadata": {},
   "source": [
    "### 11.4 K-means with cluster number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7438828d-5fcd-459d-b2eb-78c01a8d3b38",
   "metadata": {},
   "source": [
    "The **kmeans** function takes two arguments.  The first one is the data. The second one is the number of centers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06149c38-3683-40b6-ac69-dd8514efb4ac",
   "metadata": {},
   "source": [
    "```{r}\n",
    "penguin_clust <- kmeans(standardized_data, centers = 3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aef795a-8303-49d1-8ea8-b7645dd763f6",
   "metadata": {},
   "source": [
    "Then the **broom** package is needed to use the **augment** function. The augment function takes in the model and the original data frame, and returns a data frame with the data and cluster assignments mutated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fc483d-169d-456c-8df1-c80ab62c20c9",
   "metadata": {},
   "source": [
    "```{r}\n",
    "library(broom)\n",
    "\n",
    "clustered_data <- augment(penguin_clust, standardized_data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c92b357-4ca2-4a7c-b405-236d69e5ca63",
   "metadata": {},
   "source": [
    "Finally, the cluster assignments can be visualized using **ggplot**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a48d66-5e2e-4785-af31-3a529e4fd3fa",
   "metadata": {},
   "source": [
    "```{r}\n",
    "cluster_plot <- ggplot(clustered_data, aes(x = flipper_length_mm, y = bill_length_mm, color = .cluster), size = 2) +\n",
    "  geom_point() +\n",
    "  labs(x = \"Flipper Length (standardized)\", y = \"Bill Length (standardized)\", color = \"Cluster\") + \n",
    "  scale_color_manual(values = c(\"dodgerblue3\", \"darkorange3\", \"goldenrod1\")) + \n",
    "  theme(text = element_text(size = 12))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8849e5-738f-4441-9a7b-882e0669e1a9",
   "metadata": {},
   "source": [
    "To find total WSSD for a model can use **glance** function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed15e39e-95b7-4a7e-b732-b716b2f90a8a",
   "metadata": {},
   "source": [
    "```{r}\n",
    "glance(penguin_clust)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366594ee-7b0e-424b-9bda-538a6162cb9e",
   "metadata": {},
   "source": [
    "### 11.5 K-means to determine cluster number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504e8ed7-0890-46a9-8976-aeadb1fbe9f0",
   "metadata": {},
   "source": [
    "To find total WSSD for variety of K values first need to create dataframe with K values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006047c8-bc38-4fd6-927a-ddec8f5715fc",
   "metadata": {},
   "source": [
    "```{r}\n",
    "penguin_clust_ks <- tibble(k = 1:9)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4b8726-eab6-4aaa-b3ba-4397f7d6c8d3",
   "metadata": {},
   "source": [
    "Then we use **rowwise** + **mutate** to apply the **kmeans** function within each row to each K. However, given that the **kmeans** function returns a model object to us (not a vector), we will need to store the results as a list column. This works because both vectors and lists are legitimate data structures for data frame columns. To do this we use **list** function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bc5267-2e1b-4988-afa8-d61f67156919",
   "metadata": {},
   "source": [
    "```{r}\n",
    "penguin_clust_ks <- tibble(k = 1:9) |>\n",
    "  rowwise() |>\n",
    "  mutate(penguin_clusts = list(kmeans(standardized_data, k)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f7eaa-0359-4f5d-bf6a-23ca698bc002",
   "metadata": {},
   "source": [
    "If we wanted to get one of the clusterings out of the list column in the data frame, use **pull**. **pull** will return to us a data frame column as a simpler data structure; here, that would be a list. To extract first item use **pluck** function. This example plucks 1."
   ]
  },
  {
   "cell_type": "raw",
   "id": "8af6ea36-2ca8-4214-b7f6-449f7b77762b",
   "metadata": {},
   "source": [
    "penguin_clust_ks |>\n",
    "  pull(penguin_clusts) |>\n",
    "  pluck(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5ddea6-8af3-4b89-b451-250c31e45a9b",
   "metadata": {},
   "source": [
    "Use mutate again to apply **glance** to each of the K-means clustering objects to get the clustering statistics (including WSSD). Since output of **glance** is dataframe must use list function again. This results in a complex data frame with 3 columns, one for K, one for the K-means clustering objects, and one for the clustering statistics:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88f26077-77c7-454c-b100-48fa7d9f1f52",
   "metadata": {},
   "source": [
    "penguin_clust_ks <- tibble(k = 1:9) |>\n",
    "  rowwise() |>\n",
    "  mutate(penguin_clusts = list(kmeans(standardized_data, k)),\n",
    "         glanced = list(glance(penguin_clusts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef5896f-1b1c-44a8-9fc8-a06600b8dd7f",
   "metadata": {},
   "source": [
    "Finally we extract the total WSSD from the column named glanced (whatever it is named). Each item in list is dataframe so we will need to use the **unnest** function to unpack the data frames into simpler column data types."
   ]
  },
  {
   "cell_type": "raw",
   "id": "68e7cf36-4c4c-4f4a-99db-7640f9d68aa6",
   "metadata": {},
   "source": [
    "clustering_statistics <- penguin_clust_ks |>\n",
    "  unnest(glanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7d3d3a-0ba6-4f49-890a-64053adaec85",
   "metadata": {},
   "source": [
    "Now that there is tot.withinss and k is same df we can create plot to determine k"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a06dd35-20b7-4ecd-8162-a67dda53527d",
   "metadata": {},
   "source": [
    "elbow_plot <- ggplot(clustering_statistics, aes(x = k, y = tot.withinss)) +\n",
    "  geom_point() +\n",
    "  geom_line() +\n",
    "  xlab(\"K\") +\n",
    "  ylab(\"Total within-cluster sum of squares\") +\n",
    "  scale_x_continuous(breaks = 1:9) + \n",
    "  theme(text = element_text(size = 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1052c4-4ca1-41cf-8833-96f32693c83f",
   "metadata": {},
   "source": [
    "To try multiple random initializations we use the **nstart** argument in the first block of code. Number of nstart depends on size/characteristics of dataset and computer power. The larger the nstart value the better from an analysis perspective, but trade-off of doing so many clusters is time. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea886074-b1ca-48ba-ae67-37a0ffa3c211",
   "metadata": {},
   "source": [
    "penguin_clust_ks <- tibble(k = 1:9) |>\n",
    "  rowwise() |>\n",
    "  mutate(penguin_clusts = list(kmeans(standardized_data, nstart = 10, k)),        IN THIS LINE\n",
    "         glanced = list(glance(penguin_clusts)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
