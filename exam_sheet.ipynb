{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80b3c9b0-7633-4d07-afbc-2d7e70a93619",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c16267b-5958-4f45-b056-936530f96f97",
   "metadata": {},
   "source": [
    "## General\n",
    "\n",
    "Clustering can be defined as a data analysis technique that involves dividing a dataset into smaller subgroups that are related in some way. \n",
    "\n",
    "Can be used to seperate: \n",
    "- Online customers into groups with similar purchasing behaviours \n",
    "- People with similar genetic properties \n",
    "- Documents that correspond to different topics \n",
    "\n",
    "It is considered an *unsupervised* task because it tries to understand data without response variables.\n",
    "\n",
    "It uses a clustering algorithm and in the end has findings that help **generate new questions** and **improve predictive analyses**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ff16ea-6975-40df-874b-a0f8ade37f2d",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b4a43d-dbbd-460f-a70a-3799a2bde565",
   "metadata": {},
   "source": [
    "K-means algorithm is a process that groups data in to *K* clusters and its measured quality is in *WSSD* (within-cluster sum-of-squared-distances).\n",
    "\n",
    "Total WSSD is determined by adding the squared distance between each of the data points and its respective cluster and taking the sum. \n",
    "\n",
    "This is the algorithm process: \n",
    "1. Begin the K-means algorithm by picking *K*, and uniformly randomly assigning data to the *K* clusters.\n",
    "2. K-means then repeatedly goes through two major steps that minimize total WSSD <br>\n",
    "**i) Center Update:** Compute the center of each cluster <br>\n",
    "**ii) Label Update:** Reassign each point to the cluster with the nearest center\n",
    "\n",
    "K-means should be repeated in a random restart to avoid being stuck in a bad solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7d2e2e-7f1f-43eb-bac0-9a148bcc72e7",
   "metadata": {},
   "source": [
    "## Data preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d1abcd-1735-4d75-b4fd-d6c94ea35087",
   "metadata": {},
   "source": [
    "```\n",
    "standardized_data <- \n",
    "    not_standardized_data |>\n",
    "    select(c(...)) |>\n",
    "    mutate(across(everything(), scale)) ##(1)##\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a874305-d32c-4ede-a0db-da2c4da4b293",
   "metadata": {},
   "source": [
    "1. Calculating distance so we should standardize the data using accross everything scale. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33628cc-4192-4c53-826f-5fa9e21d27b7",
   "metadata": {},
   "source": [
    "## With K value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a847ef-64d6-4a82-8dc1-de7fdc01c459",
   "metadata": {},
   "source": [
    "```\n",
    "library(broom) ##(1)##\n",
    "\n",
    "kmeans_object <- kmeans(standardized_data, centers = 3) ##(2)##\n",
    "\n",
    "clustered_data <- augment(kmeans_object, standardized_data) ##(3)##\n",
    "\n",
    "cluster_plot <- ggplot(clustered_data, aes(x = VALUE, y = VALUE, color = .cluster), size = 2) + ##(4)##\n",
    "  geom_point() +\n",
    "  labs(x = \"VALUE\", y = \"VALUE\", color = \"Cluster\") + \n",
    "  scale_color_manual(values = c(\"dodgerblue3\", \"darkorange3\", \"goldenrod1\")) + \n",
    "  theme(text = element_text(size = 12))\n",
    "\n",
    "glance(kmeans_object) ##(5)##\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc99d36-9527-408c-91d1-03e4d6ad4c06",
   "metadata": {},
   "source": [
    "1. The broom package allows us to use the **augment** function. \n",
    "2. Kmeans goes through the process that assigns data points. \n",
    "3. Augment takes in the model and original df, and returns df with data and cluster assignments mutated. \n",
    "4. Visualization with cluster assignments for the cluster. \n",
    "5. Glance can be used on kmeans_object to find total WSSD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd593457-bc4a-4768-9eb0-9b346da1104d",
   "metadata": {},
   "source": [
    "## Without K value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383afada-7bda-42f2-ab80-41552e65e26f",
   "metadata": {},
   "source": [
    "```\n",
    "##(1)##\n",
    "elbow_stats <-  tibble(k = 1:10) |>\n",
    " rowwise() |>\n",
    " mutate(clusters = list(kmeans(standardized_data, centers = k, nstart = ...)), \n",
    " glanced = list(glance(clusters)))                                           \n",
    "\n",
    "##(2)##\n",
    "clustering_statistics <- elbow_stats |>\n",
    " select(-clusters) |>\n",
    " unnest(glanced)\n",
    "\n",
    "##(3)##\n",
    "elbow_plot <- ggplot(clustering_statistics, aes(x = k, y = tot.withinss)) +\n",
    " geom_point(size = 2) +\n",
    " geom_line() +\n",
    " labs(x = \"K\",\n",
    "      y = \"Total within-cluster sum of squares\",\n",
    "      title = \"Elbow Plot\") +\n",
    " scale_x_continuous(breaks = 1:10) +\n",
    " theme(text = element_text(size = 20))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e955f78-4df6-497d-b828-ae9017271107",
   "metadata": {},
   "source": [
    "1. Get Kmeans object for each k value in a given tibble range that we want (perform operations on each row with a k value we want it to use). \n",
    "2. Unnest because each item in this column is a dataframe. \n",
    "3. Visualize the elbow plot so that we can choose a good k value for our analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fcfbe1-90f8-42f4-ad23-cc88ed629576",
   "metadata": {},
   "source": [
    "# Inference I (Statistical Inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76c98f8-c6e2-49a8-8ef4-1d47e236b4bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fd364d-0e1c-4f83-8a3a-ce921b685586",
   "metadata": {},
   "source": [
    "| Terms |  Definitions |\n",
    "|----------------|------------|\n",
    "| <p align=\"left\">Mean | <p align=\"left\">The sum of all of the data observations divided by number of observations. |\n",
    "| <p align=\"left\">Median | <p align=\"left\">The middle observation of a sorted variable’s data. Count half from the right or left. |\n",
    "| <p align=\"left\">Variance | <p align=\"left\">The mean of the sum of the squared distances of each observation from the mean value of all observations. |\n",
    "| <p align=\"left\">Standard deviation | <p align=\"left\">The square root of the variance. |\n",
    "| <p align=\"left\">Proportion | <p align=\"left\">The number of entities/object with a specific characteristic divided by the total number of entities/objects. |\n",
    "| <p align=\"left\">Observation |  <p align=\"left\">A quantity or quality (or a set of these) from a single member of a population. |\n",
    "| <p align=\"left\">Population | <p align=\"left\">The entire set of entities/objects of interest. |\n",
    "| <p align=\"left\">Population Parameter | <p align=\"left\">A numerical summary value about the population. <p align=\"left\">_(Directly computing population parameters is often time-consuming and costly, and sometimes impossible)_ |\n",
    "| <p align=\"left\">Sample | <p align=\"left\">A subset of entities/objects in the population |\n",
    "| <p align=\"left\">Point Estimate | <p align=\"left\"> A single-value/statistic calculated from sample data that estimates an unknown population parameter of interest. <p align=\"left\">For example, the sample mean $\\bar{x}$ is a point estimate of the population mean $\\mu$. Similarly, the sample proportion $p$ is a point estimate of the population proportion $P$. <p align=\"left\">_(High variation in the sampling distribution of the sample mean causes point estimate to be unreliable.)_|\n",
    "| <p align=\"left\">Statistical Inference | <p align=\"left\">The process of using a sample to make a conclusion about the broader population from which it is taken is referred to as statistical inference. |\n",
    "| <p align=\"left\">Sample Variablity | <p align=\"left\">Estimates vary from sample to sample due to sampling variability.   |\n",
    "| <p align=\"left\">Sampling Distribution | <p align=\"left\">A distribution of point estimates, where each point estimate was calculated from a different random sample from the same population. |\n",
    "| <p align=\"left\">Random sampling | <p align=\"left\">electing a subset of observations from a population where each observation is equally likely to be selected at any point during the selection process. |\n",
    "| <p align=\"left\">Representative sampling | <p align=\"left\">selecting a subset of observations from a population where the sample’s characteristics are a good representation of the population’s characteristics |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf133409-79b6-44fd-9be1-54e050900234",
   "metadata": {},
   "source": [
    "## Sample Size "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7e1b70-ea19-4bbc-9d0c-690e31675b0d",
   "metadata": {},
   "source": [
    "1) The mean of the sample mean (across all samples) is equal to the population mean. In other words, the sampling distribution is centred at the population mean.\n",
    "2) Increasing the size of the sample decreases the spread (i.e., the variability) of the sampling distribution making it more narrow. Therefore, a larger sample size results in a more reliable point estimate of the population parameter.\n",
    "3) The distribution of the sample mean is roughly bell-shaped once the sample size is large enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d33afe9-e177-466d-b9b0-ae9e277af957",
   "metadata": {},
   "source": [
    "## Sampling Distribution (for sample mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bd5086-ddfb-4337-8c4c-7a6b088f001f",
   "metadata": {},
   "source": [
    "```\n",
    "samples <- rep_sample_n(airbnb, size = 40, reps = 20000) ##(1)##\n",
    "\n",
    "sample_estimates <- samples |>  ##(2)##\n",
    "  group_by(replicate) |>\n",
    "  summarize(sample_mean = mean(price))\n",
    "\n",
    "sampling_distribution_40 <- ggplot(sample_estimates, aes(x = sample_mean)) +   ##(3)##\n",
    "  geom_histogram(fill = \"dodgerblue3\", color = \"lightgrey\") +\n",
    "  xlab(\"Sample mean price per night ($)\") +\n",
    "  theme(text = element_text(size = 20))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c79163a-9a27-4fbe-86b6-130d8b679d55",
   "metadata": {},
   "source": [
    "1. Take 20000 samples of size 40 out of the population \n",
    "2. Group by their sample number and find the mean \n",
    "3. Plot the sample means on a histogram "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364aa678-deb6-4ac4-9689-6da169f301d1",
   "metadata": {},
   "source": [
    "# Inference II (Bootstrapping and Confidence Intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71f8306-d0fd-432c-8a74-1c50067c7f70",
   "metadata": {},
   "source": [
    "## Bootstrapping Overview "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3a25dd-50dd-44c7-aeed-290038fe15e9",
   "metadata": {},
   "source": [
    "The concept of sampling from our original one sample with replacement to get a bootstrapping distribution.\n",
    "\n",
    "The original sample acts as a population and with bootstrapping we can get an approximation for the sampling distribution. \n",
    "\n",
    "Useful if we can only get one sample from the population. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4502e4c-56d7-402f-a82c-44ccc4684754",
   "metadata": {},
   "source": [
    "## How to create bootstrapping distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e6eae-b2aa-4d1b-9a71-19c7425e0bd3",
   "metadata": {},
   "source": [
    "For a sample of size *n*: \n",
    "1. Randomly select an observation drawn from the original sample \n",
    "2. Record its value \n",
    "3. Replace it \n",
    "4. Repeat steps 1-3 until you have *n* observations \n",
    "5. Record the bootstrap point estimate you want \n",
    "6. Repeat steps 1-5 many times to create an approximate sampling distribution. \n",
    "7. Calculate plausibe ranges "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2cfc26-f805-4a32-92c0-ba140ad5e0f2",
   "metadata": {},
   "source": [
    "```\n",
    "boot20000 <- one_sample |>\n",
    "  rep_sample_n(size = 40, replace = TRUE, reps = 20000)\n",
    "\n",
    "boot20000_means <- boot20000 |>\n",
    "  group_by(replicate) |>\n",
    "  summarize(mean = mean(price))\n",
    "\n",
    "boot_est_dist <- ggplot(boot20000_means, aes(x = mean)) +\n",
    "  geom_histogram(fill = \"dodgerblue3\", color = \"lightgrey\") +\n",
    "  xlab(\"Sample mean price per night ($)\") +\n",
    "  ggtitle(\"Bootstrap Distribution\") +\n",
    "  theme(text = element_text(size = 20))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d647eba7-9b97-4194-8d23-ead3a025cb1c",
   "metadata": {},
   "source": [
    "## Comparison to true sampling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27c4736-1aad-4500-92ac-9bc24a5939f5",
   "metadata": {},
   "source": [
    "1. The shape and spread of the true sampling distribution and the sampling distribution should be similar.\n",
    "2. The mean of the bootstrap distribution is not the same as the mean of the sampling distribution because boostrap was sampled from a sample and sampling distribution is sampled from population. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4e6883-a551-477b-b201-b2bb910070a2",
   "metadata": {},
   "source": [
    "## Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f6ca2a-70e3-4d91-b3e2-e644e2bffeac",
   "metadata": {},
   "source": [
    "- One should think of a confidence interval as a range of plausible values for the population parameter, which may or may not fall within the interval. This is significantly different than a point estimate, which is a single plausible value for the population parameter.\n",
    "- We can interpret a 90% confidence interval as: we are 90% confident that the true mean is captured by the interval. Or, in other words, across all 90% confidence intervals that could be calculated for the mean of the population of interest, we can expect that 90% of the intervals contain the true mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8093c3-ab67-4892-828d-2166aaa756fe",
   "metadata": {},
   "source": [
    "```\n",
    "bounds <- boot20000_means |>\n",
    "  select(mean) |>\n",
    "  pull() |>\n",
    "  quantile(c(0.025, 0.975))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b02284d-26da-4e8d-9a78-3a44268d6bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
